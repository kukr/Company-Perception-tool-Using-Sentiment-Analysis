{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install webdriver-manager selenium lzma\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "import time\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Installing and running chrome webdriver\")\n",
    "driver = webdriver.Chrome(ChromeDriverManager().install())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indeedCompanyBaseURL = 'https://www.indeed.com/'\n",
    "\n",
    "# Change these constants\n",
    "# Note - do not set the number of reviews to scrape per company over 150\n",
    "# Otherwise indeed.com will block the scraper, by temporarily blocking your IP Address\n",
    "# Trust me, I found out the hard way\n",
    "# Number of Reviews needs to be in multiples of 20\n",
    "NUMBER_OF_COMPANIES_TO_SCRAPE = 150\n",
    "NUMBER_OF_REVIEWS_TO_SCRAPE_PER_COMPANY = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "companyURLs = {}\n",
    "print(\"Beginning to scrape\")\n",
    "companyScraperBaseURL = 'https://www.indeed.com/jobs?q=software+intern&start='\n",
    "for i in range(0,NUMBER_OF_COMPANIES_TO_SCRAPE,10):\n",
    "    print(\"Scraping companies - \",i+10,\"/\",NUMBER_OF_COMPANIES_TO_SCRAPE)\n",
    "    url = companyScraperBaseURL+str(i)\n",
    "    driver.get(url)\n",
    "    time.sleep(1)\n",
    "    companies = driver.find_elements(By.CLASS_NAME,'companyOverviewLink')\n",
    "    for company in companies:\n",
    "        if company.text not in companyURLs:\n",
    "            companyURLs[company.text] = (company.get_property('href'))\n",
    "\n",
    "print(\"Company Scraping done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews = {}\n",
    "\n",
    "for i,company in enumerate(companyURLs):\n",
    "    url = companyURLs[company]\n",
    "    print()\n",
    "    print(\"({0}/{1}) Scraping company reviews - {2}\".format(i+1, len(companyURLs), company))\n",
    "    for i in range(0,NUMBER_OF_REVIEWS_TO_SCRAPE_PER_COMPANY,20):\n",
    "        print(\"Progress - \",i+20,\"/\",NUMBER_OF_REVIEWS_TO_SCRAPE_PER_COMPANY)\n",
    "        newUrl = url+'/reviews?&start='+str(i)\n",
    "        driver.get(newUrl)\n",
    "        elems = driver.find_elements(By.CLASS_NAME,'eu4oa1w0')\n",
    "        for elem in elems:\n",
    "            if elem.tag_name==\"span\":\n",
    "                txt = elem.text\n",
    "                if txt!='':\n",
    "                    if company not in reviews:\n",
    "                        reviews[company] = ''\n",
    "                    reviews[company]+=' '+txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame()\n",
    "for company in reviews:\n",
    "    tempm = {}\n",
    "    tempm['Company'] = company\n",
    "    tempm['Reviews'] = reviews[company]\n",
    "    df = df.append(tempm, ignore_index=True)\n",
    "\n",
    "df.to_csv('../dataset/out.csv',sep='|', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.4 64-bit ('3.9.4')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4 (default, Aug  4 2021, 21:42:27) \n[Clang 12.0.5 (clang-1205.0.22.11)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "cf848db52ef32cc176ed1af497719705d0e2fe62659246413983ac6a5ce0226f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
